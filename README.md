# SignLanguageApp

- **frontend/**: Built with React Native (using Expo), allows users to capture hand gestures via camera and display translated results.
- **backend/**: Powered by FastAPI and Python, handles image processing and prediction using a trained machine learning model.

---

## ğŸš€ Features

- ğŸ¥ Real-time hand gesture capture
- ğŸ”¤ Instant translation of sign language to text
- ğŸ¤– Machine learningâ€“based image classification
- ğŸ“¡ REST API communication between frontend and backend
- ğŸ§ Focused on accessibility for the DHH community

---

## ğŸ› ï¸ Tech Stack

| Layer     | Technology                     |
|-----------|--------------------------------|
| Frontend  | React Native, Expo, JavaScript |
| Backend   | FastAPI, Python, Uvicorn       |
| ML/Tools  | OpenCV, NumPy, PIL, custom model |

---

## ğŸ”§ Getting Started

### âœ… Prerequisites

- Node.js & npm
- Python 3.8+
- Git
- Expo CLI (`npm install -g expo-cli`)
- A smartphone or emulator (for testing)

---

### âš™ï¸ Backend Setup (FastAPI)

```bash
cd backend
python -m venv venv
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

pip install -r requirements.txt
uvicorn main:app --reload
